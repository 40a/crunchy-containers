<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="generator" content="AsciiDoc 8.6.8, bootstrap backend 4.5.0">
    <title>Kubernetes Examples - Crunchy Containers for PostgreSQL</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Crunchy Data Solutions, Inc.">
    <!-- AsciiDoc Bootstrap styles -->
    <link rel="stylesheet" type="text/css" id="bootstrapTheme" href="./stylesheets/asciidoc-bootstrap.min.css">
    <!-- Back to top (jquery plugin) -->
    <link rel="stylesheet" type="text/css" href="./stylesheets/ui.totop.css">

    <!--[if (lt IE 9) & (!IEMobile)]>
        <script src="./javascripts/html5shiv.min.js"></script>
        <script src="./javascripts/respond.min.js"></script>
    <![endif]-->

  </head>
  <body id="toc-top">
    <div id="page">


      <div class="jumbotron">
        <div class="container">
          <h1>Kubernetes Examples - Crunchy Containers for PostgreSQL</h1>
        </div>
      </div>

  <div id="content" class="container">

    <div class="row">




        <div class="col-md-9" role="main">
<div class="section">
    <h1 class="page-header" id="kube_environment">1. Kube Environment</h1>
<div class="paragraph"><p>Here are instructions for running examples on a pure kube cluster.</p></div>
<h2 id="installation">1.1. Installation</h2>
<div class="paragraph"><p>Some steps to follow:</p></div>
<h3 id="install_kube_1_2_4_by_source_on_a_centos_7_vm">1.1.1. Install Kube 1.2.4 by source on a Centos 7 VM.</h3>
<div class="literalblock">
<div class="content monospaced">
<pre>sudo yum -y install etcd-2.2.5
git clone https://github.com/kubernetes/kubernetes.git
cd kubernetes
git checkout v1.2.4
make release-skip-tests
export PATH=$PATH:~/kubernetes/_output/release-stage/client/linux-amd64/kubernetes/client/bin</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
Turn off selinux, there is a policy in place that prevents local registry
lookups, need to figure this out.
</p>
</li>
</ul></div>
<h3 id="setup_dns">1.1.2. Setup DNS</h3>
<div class="paragraph"><p>edit hack/local-up-cluster.sh</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>ENABLE_CLUSTER_DNS=true
DNS_SERVER_IP="10.0.0.10"
DNS_DOMAIN="cluster.local"</pre>
</div></div>
<div class="paragraph"><p>edit /etc/resolv.conf or configure your network settings to add
the DNS server</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>search default.svc.cluster.local crunchy.lab
nameserver 10.0.0.10</pre>
</div></div>
<h2 id="run_kube">1.2. Run Kube</h2>
<div class="literalblock">
<div class="content monospaced">
<pre>sudo ./hack/local-up-cluster.sh</pre>
</div></div>
<h2 id="old_notes_not_used">1.3. Old Notes Not Used!!</h2>
<div class="ulist"><ul>
<li>
<p>
kubectl.sh create ns kube-system
</p>
</li>
<li>
<p>
install the skydns for kube, see kube docs and skydns.yaml example
</p>
</li>
<li>
<p>
to get emptyDir permissions to work for Deployments, I had
to remove the SecurityContextDeny admission from the hack/local-cluster-up.sh
script then use fsGroup set to 26
</p>
</li>
</ul></div>
</div>
<div class="section">
    <h1 class="page-header" id="examples_for_the_kube_environment">2. Examples for the Kube Environment</h1>
<div class="paragraph"><p>The examples/kube directory containers examples for
running the Crunchy containers in a kube environment.</p></div>
<div class="paragraph"><p>The examples are explained below.</p></div>
<h2 id="kube_example_1_single_master">2.1. Kube Example 1 - single-master</h2>
<div class="paragraph"><p>This example starts a single postgres container and service, the most simple
of examples.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/single-master/run.sh
kubectl get pod single-master
kubectl get service single-master
kubectl logs single-master</pre>
</div></div>
<div class="paragraph"><p>After the database starts up you can connect to it as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h single-master -U postgres postgres</pre>
</div></div>
<h2 id="kube_example_2_master_slave">2.2. Kube Example 2 - master-slave</h2>
<div class="paragraph"><p>This example starts a master pod, master service, slave pod, and slave
service.  The slave is a replica of the master.  This example uses
emptyDir volumes for persistence.  This example does not allow
you to scale up the slaves.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/master-slave/run.sh</pre>
</div></div>
<div class="paragraph"><p>It takes about a minute for the slave to begin replicating with the
master.  To test out replication, see if replication is underway
with this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master -U postgres postgres -c 'table pg_stat_replication'</pre>
</div></div>
<div class="paragraph"><p>If you see a line returned from that query it means the master is replicating
to the slave.  Try creating some data on the master:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master -U postgres postgres -c 'create table foo (id int)'
psql -h master -U postgres postgres -c 'insert into foo values (1)'</pre>
</div></div>
<div class="paragraph"><p>Then verify that the data is replicated to the slave:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h slave -U postgres postgres -c 'table foo'</pre>
</div></div>
<h2 id="kube_example_3_master_slave_dc">2.3. Kube Example 3 - master-slave-dc</h2>
<div class="paragraph"><p>This example starts a master pod, master service, slave pod, and slave
service.  The slave is a replica of the master.  This example uses
emptyDir volumes for persistence.  This example runs the slaves in a
Deployment.  A deployment controller lets you scale up the slaves and
create an initial replica set.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/master-slave-dc/run.sh</pre>
</div></div>
<div class="paragraph"><p>You can insert data in the master and make sure it replicates to
the slaves using the commands from Example 2 above.  Replace
<strong>master</strong> with the <strong>master-dc</strong> name and <strong>slave</strong> with <strong>slave-dc</strong>.</p></div>
<div class="paragraph"><p>This example creates 2 replicas when it initially starts.  To scale
up the number of slaves, run this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get deployment
kubectl scale --current-replicas=2 --replicas=3 deployment/slave-dc
kubectl get deployment
kubectl get pod</pre>
</div></div>
<div class="paragraph"><p>You can verify that you now have 3 replicas by running this query
on the master:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master-dc -U postgres postgres -c 'table pg_stat_replication'</pre>
</div></div>
<h2 id="kube_example_4_master_slave_rc">2.4. Kube Example 4 - master-slave-rc</h2>
<div class="paragraph"><p>This example starts a master pod, master service, slave pod, and slave
service.  The slave is a replica of the master.  This example uses
emptyDir volumes for persistence.  This example runs the slaves in a
Replication Controller.  A replication controller lets you scale up the slaves and create an initial replica set.  Deployments will likely be the
preferred way to create a replica set going forward but I wanted to
provide an example for completness sake.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/master-slave-rc/run.sh</pre>
</div></div>
<div class="paragraph"><p>You can also scale up the number of replicas using this replication
controller mechanism.  The command to scale up is as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get rc
kubectl scale rc slave-rc --replicas=3
kubectl get pod</pre>
</div></div>
<h2 id="kube_example_5_backup_job">2.5. Kube Example 5 - backup-job</h2>
<div class="paragraph"><p>This example depends on the single-master example be run prior to
this example!</p></div>
<div class="paragraph"><p>This example performs a database backup on the single-master database.
The backup is stored in the /nfsfileshare backup path which is also
a dependency.  See the installation docs on how to set up the NFS
server on this host.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/backup-job-nfs/run.sh</pre>
</div></div>
<div class="paragraph"><p>Things to point out with this example include its use of persistent
volumes and volume claims to store the backup data files to
an NFS server.</p></div>
<div class="paragraph"><p>You can view the persistent volume information as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get pvc
kubectl get pv</pre>
</div></div>
<div class="paragraph"><p>The Kube Job type executes a pod and then the pod exits.  You can
view the Job status using this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get job</pre>
</div></div>
<div class="paragraph"><p>While the backup pod is running, you can view the pod as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get pod</pre>
</div></div>
<div class="paragraph"><p>You should find the backup archive in this location:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>ls /nfsfileshare/single-master</pre>
</div></div>
<h3 id="tip">2.5.1. Tip</h3>
<div class="paragraph"><p>You can view the backup pod log using the <strong>docker logs</strong> command
on the exited container. Use <strong>docker ps -a | grep backup</strong> to
locate the container.</p></div>
<h2 id="kube_example_6_badger">2.6. Kube Example 6 - badger</h2>
<div class="paragraph"><p>This example runs a pod that includes a database container and
a pgbadger container. A service is also created for the pod.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/badger/run.sh</pre>
</div></div>
<div class="paragraph"><p>You can access pgbadger at:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>curl http://badger:10000/api/badgergenerate</pre>
</div></div>
<h3 id="tips">2.6.1. Tips</h3>
<div class="paragraph"><p>You can view the database container logs using this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl logs -c server badger</pre>
</div></div>
<h2 id="kube_example_6_metrics">2.7. Kube Example 6 - metrics</h2>
<div class="paragraph"><p>This examples starts up prometheus, grafana, and prometheus gateway.</p></div>
<div class="paragraph"><p>It is required to view or capture metrics collected by crunchy-collect.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/metrics/run.sh</pre>
</div></div>
<div class="paragraph"><p>This will start up 3 containers and services:</p></div>
<div class="ulist"><ul>
<li>
<p>
prometheus (<a href="http://crunchy-prometheus:9090">http://crunchy-prometheus:9090</a>)
</p>
</li>
<li>
<p>
prometheus gateway (<a href="http://crunchy-promgateway:9091">http://crunchy-promgateway:9091</a>)
</p>
</li>
<li>
<p>
grafana (<a href="http://crunchy-grafana:3000">http://crunchy-grafana:3000</a>)
</p>
</li>
</ul></div>
<div class="paragraph"><p>If you want your metrics and dashboards to persist to NFS, run
this script:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/metrics/run-nfs.sh</pre>
</div></div>
<div class="paragraph"><p>In the docs folder of the github repo, check out the metrics.asciidoc
for details on the exact metrics being collected.</p></div>
<h2 id="kube_example_7_collect">2.8. Kube Example 7 - collect</h2>
<div class="paragraph"><p>This example assumes you have run the metrics example which
starts up prometheus, grafana, and prometheus gateway.</p></div>
<div class="paragraph"><p>This example runs a pod that includes a database container and
a metrics collection container. A service is also created for the pod.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/collect/run.sh</pre>
</div></div>
<div class="paragraph"><p>You can view the collect container logs using this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl logs -c collect master-collect</pre>
</div></div>
<div class="paragraph"><p>You can access the database or drive load against it using
this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master-collect -U postgres postgres</pre>
</div></div>
<h2 id="kube_example_8_vacuum_job">2.9. Kube Example 8 - vacuum-job</h2>
<div class="paragraph"><p>This example assumes you have run the single-master example prior
to this example!</p></div>
<div class="paragraph"><p>This example runs a Job which performs a SQL VACUUM on a particular
table (testtable) in the single-master database instance.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/vacuum-job/run.sh</pre>
</div></div>
<div class="paragraph"><p>Verify the job completed:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl get job</pre>
</div></div>
<div class="paragraph"><p>Look at the docker log of the vacuum job&#8217;s pod:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>docker logs $(docker ps -a | grep crunchy-vacuum | cut -f 1 -d' ')</pre>
</div></div>
<h2 id="kube_example_9_pgpool">2.10. Kube Example 9 - pgpool</h2>
<div class="paragraph"><p>This example assumes you have run the master-slave example prior
to this example!</p></div>
<div class="paragraph"><p>This example runs a pgpool pod that creates a special purpose
proxy to a postgres cluster (master and slave).</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/pgpool/run.sh</pre>
</div></div>
<div class="paragraph"><p>The example is configured to allow the <strong>testuser</strong> to connect
to the <strong>userdb</strong> database as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h pgpool -U testuser userdb</pre>
</div></div>
<h2 id="kube_example_10_master_restore">2.11. Kube Example 10 - master-restore</h2>
<div class="paragraph"><p>This example assumes you have run the backup-job example prior
to this example!  You will need to find a backup you want to
use for running this example, you will need the timestamped directory
path under /nfsfileshare/single-master/.  Edit the master-restore.json
file and update the BACKUP_PATH setting to specify the
NFS backup path you want to restore with, example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>"name": "BACKUP_PATH",
"value": "single-master/2016-05-27-14-35-33"</pre>
</div></div>
<div class="paragraph"><p>This example runs a postgres container passing in the backup location.
The startup of the container will use rsync to copy the backup data
to this new container, and then launch postgres which will use the
backup data to startup with.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/master-restore/run.sh</pre>
</div></div>
<div class="paragraph"><p>Test the restored database as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h restored-master -U postgres postgres</pre>
</div></div>
<h2 id="kube_example_11_watch">2.12. Kube Example 11 - watch</h2>
<div class="paragraph"><p>This example assumes you have run the master-slave example prior
to this example!</p></div>
<div class="paragraph"><p>This example runs a crunchy-watch container to look for the
master within a postgres cluster, if it can not find the master it
will proceed to cause a failover to a slave.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/watch/run.sh</pre>
</div></div>
<div class="paragraph"><p>Check out the log of the watch container as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl log watch</pre>
</div></div>
<div class="paragraph"><p>Then trigger a failover using this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl delete pod master</pre>
</div></div>
<div class="paragraph"><p>Resume watching the watch container&#8217;s log and verify that it
detects the master is not reachable and performs a failover
on the slave.</p></div>
<div class="paragraph"><p>A final test is to see if the old slave is now a fully functioning
master by inserting some test data into it as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master -U postgres postgres -c 'create table failtest (id int)'</pre>
</div></div>
<div class="paragraph"><p>The above command still works because the watch container has
changed the labels of the slave to make it a master, so the master
service will still work and route now to the new master even though
the pod is named slave.</p></div>
<h3 id="tip_2">2.12.1. Tip</h3>
<div class="paragraph"><p>You can view the lables on a pod with this command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl describe pod slave | grep Label</pre>
</div></div>
<h2 id="kube_example_11_pgbouncer">2.13. Kube Example 11 - pgbouncer</h2>
<div class="paragraph"><p>This example assumes you have run the master-slave example prior
to this example!</p></div>
<div class="paragraph"><p>This example runs a crunchy-pgbouncer container to look for the
master within a postgres cluster, if it can not find the master it
will proceed to cause a failover to a slave.  It will also configure
a pgbouncer container that sets up a connection pool to the
configured master and slave.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/pgbouncer/run.sh</pre>
</div></div>
<div class="paragraph"><p>Connect to the <strong>master</strong> and <strong>slave</strong> databases as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h pgbouncer -U postgres master
psql -h pgbouncer -U postgres slave</pre>
</div></div>
<div class="paragraph"><p>The names <strong>master</strong> and <strong>slave</strong> are pgbouncer configured names
and don&#8217;t necessarily have to match the database name in the
actual Postgres instance.</p></div>
<div class="paragraph"><p>View the pgbouncer log as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl log pgbouncer</pre>
</div></div>
<div class="paragraph"><p>Next, test the failover capability within the crunchy-watch
container using the following:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>kubectl delete pod master</pre>
</div></div>
<div class="paragraph"><p>Take another look at the pgbouncer log and you will see it trigger
the failover to the slave pod.  After this failover
you should be able to execute the command:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h pgbouncer -U postgres master</pre>
</div></div>
<h2 id="kube_example_12_synchrounous_slave">2.14. Kube Example 12 - synchrounous slave</h2>
<div class="paragraph"><p>This example deploys a PostgreSQL cluster with a master,
a synchrounous slave, and an asynchronous slave.  The
two slaves share the same Service.</p></div>
<div class="paragraph"><p>Running the example:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>examples/kube/sync/run.sh</pre>
</div></div>
<div class="paragraph"><p>Connect to the <strong>master</strong> and <strong>slave</strong> databases as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>psql -h master -U postgres postgres -c 'create table mister (id int)'
psql -h master -U postgres postgres -c 'insert into mister values (1)'
psql -h master -U postgres postgres -c 'table pg_stat_replication'
psql -h slave -U postgres postgres -c 'select inet_server_addr(), * from mister'
psql -h slave -U postgres postgres -c 'select inet_server_addr(), * from mister'
psql -h slave -U postgres postgres -c 'select inet_server_addr(), * from mister'</pre>
</div></div>
<div class="paragraph"><p>This set of queries will show you the IP address of the Postgres slave
container, notice it changes because of the round-robin Service proxy
we are using for both slaves.  The example queries also show that both
slaves are replicating from the master.</p></div>
<h2 id="tip_1">2.15. Tip 1</h2>
<div class="paragraph"><p>create a static route from your host to 10.0.0.0/16 if you
want to test the user interfaces of the metrics tools</p></div>
<div class="paragraph"><p>On my host, 114, and my bridge, br1, this worked for me:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre> ip route add 10.0.0.0/16 via 192.168.0.114 dev br1</pre>
</div></div>
</div>
<div class="section">
    <h1 class="page-header" id="legal_notices">3. Legal Notices</h1>
<div class="paragraph"><p>Copyright © 2016 Crunchy Data Solutions, Inc.</p></div>
<div class="paragraph"><p>CRUNCHY DATA SOLUTIONS, INC. PROVIDES THIS GUIDE "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.</p></div>
<div class="paragraph"><p>Crunchy, Crunchy Data Solutions, Inc. and the Crunchy Hippo Logo are trademarks of Crunchy Data Solutions, Inc.</p></div>
</div>
        </div>  <!-- /.col-md-9 -->
        <div class="col-md-3">
        <div id="sidebar">
    <div class="toc2">
<div class="panel panel-default">
<div class="panel-heading">Table of Contents</div>
<div class="panel-body" id="toc">
</div>
</div>
    </div>
</div>
        </div>  <!-- /.col-md-3 -->
    </div>  <!-- /.row -->

  </div>  <!-- /.container -->

    <footer id="footer" role="contentinfo">
        <div class="container">
<div class="row"><div id="footnotes"></div></div>
        <table>
        <tr>
        <td><b>Crunchy Data Solutions, Inc.</b></td>
        <td>v1.0.3</td>
        <td>February 27, 2016</td>
        </tr>
        </table>
        </div>
    </footer>

    <script src="./javascripts/jquery.min.js"></script>
    <script src="./bootstrap/js/bootstrap.min.js"></script>
    <script src="./javascripts/asciidoc.js"></script>
    <!-- Install TOC and/or footnotes (if necessary) -->
    <script type="text/javascript">asciidoc.install(2);</script>

    <script src="./javascripts/jquery.ui.totop.min.js"></script>



    <!-- Remove footnotes if empty block -->
    <script type="text/javascript">$(function(){ if ($("#footnotes div").length == 0) $("#footnotes").parent().remove(); });</script>

    <script type="text/javascript">$(function(){ if ($("#dropdown-menu-versions")) $("#dropdown-menu-versions").parent().remove(); });</script>

    <script type="text/javascript">$(function(){ $().UItoTop(); });</script>
    </div> <!-- page -->
  </body>
</html>
